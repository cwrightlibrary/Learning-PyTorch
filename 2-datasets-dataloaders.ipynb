{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "56264aa4",
   "metadata": {},
   "source": [
    "# [PyTorch - Learning the Basics](https://pytorch.org/tutorials/beginner/basics/intro.html)\n",
    "\n",
    "This is part two from the basics."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71d0a111",
   "metadata": {},
   "source": [
    "## Datasets & DataLoaders\n",
    "\n",
    "To keep our model training code readable and modular, we want to decouple our dataset code from the model training code. Otherwise, code for processing data samples can get messy and difficult to maintain. There are two data primitives in PyTorch: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset`. These allow you to use pre-loaded datasets as well as your own data. `Dataset` stores the samples and their corresponding labels, and `DataLoader` wraps an iterable around the `Dataset` to enable easy access to the samples.\n",
    "\n",
    "There are a number of pre-loaded datasets in the PyTorch domain libraries that subclass `torch.utils.data.Dataset` and implement funtions specific to the particular data. They can be used to prototype and benchmark your own model and can be found here:\n",
    "\n",
    "- [Image Datasets](https://pytorch.org/vision/stable/datasets.html)\n",
    "- [Text Datasets](https://pytorch.org/text/stable/datasets.html)\n",
    "- [Audio Datasets](https://pytorch.org/audio/stable/datasets.html)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bca7f054",
   "metadata": {},
   "source": [
    "### Loading a `Dataset`\n",
    "\n",
    "Below is an example of how to load the [Fashion-MNIST](https://research.zalando.com/project/fashion_mnist/fashion_mnist/) dataset from TorchVision. This dataset of Zalando's article images consisting of 60,000 training examples and 10,000 test examples. Each example comprises a 28x28 grayscale image and an associated label from one of 10 classes.\n",
    "\n",
    "**We load the [FashionMNIST Dataset](https://pytorch.org/vision/stable/datasets.html#fashion-mnist) with the following parameters:**\n",
    "\n",
    "- `root` is the path where the train/test data is stored,\n",
    "- `train` specifies training or test dataset,\n",
    "- `download=True` downloads the data from the internet if it's not available at `root`.\n",
    "- `transform` and `target_transform` specify the feature and label transformations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d7f67adf",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n",
      "100.0%\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.utils.data import Dataset\n",
    "from torchvision import datasets\n",
    "from torchvision.transforms import ToTensor\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "training_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")\n",
    "\n",
    "test_data = datasets.FashionMNIST(\n",
    "    root=\"data\",\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=ToTensor()\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ad5879c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
